head(20)
# Extract general statistics for each team
team_stats_list <- page %>%
html_nodes("div.article-body p") %>%
html_text() %>%
grep("Overturns: ", ., value = TRUE)
library(rvest)
library(dplyr)
library(stringr)
library(tidyr)
# Define the URL
VAR_PAGE_2020_2021 <- "https://www.espn.co.uk/football/story/_/id/37619801/how-var-decisions-affected-every-premier-league-club-2021-22"
# Read the webpage
page <- read_html(VAR_PAGE_2020_2021)
VAR_team <- page %>%
html_nodes("aside.inline.editorial.float-r") %>%
html_text()
VAR_team <- VAR_team[2:3]
split_lines <- strsplit(VAR_team, "\n")
split_lines <- lapply(split_lines, function(x) x[-1])
print(split_lines)
decisions_for <- list(split_lines[[1]])
library(rvest)
library(dplyr)
library(stringr)
# Define the URL
VAR_PAGE_2020_2021 <- "https://www.espn.co.uk/football/story/_/id/37619801/how-var-decisions-affected-every-premier-league-club-2021-22"
# Read the webpage
page <- read_html(VAR_PAGE_2020_2021)
team_list <- page %>%
html_nodes("div.article-body h2") %>%
html_text() %>%
gsub("\\s+$", "", .) %>%  # Remove extra spaces at the end
gsub("[^a-zA-Z]+$", "", .) %>%
gsub("^Editor's Picks|How to fix VAR.*|The ultimate guide.*|ESPN's .*|Marcotti: .*", "", .) %>%
unique()
team_list <- team_list[team_list != ""]
print(team_list)
library(rvest)
library(dplyr)
library(stringr)
# Define the URL
VAR_PAGE_2020_2021 <- "https://www.espn.co.uk/football/story/_/id/37619801/how-var-decisions-affected-every-premier-league-club-2021-22"
# Read the webpage
page <- read_html(VAR_PAGE_2020_2021)
team_list <- page %>%
html_nodes("div.article-body h2") %>%
html_text() %>%
gsub("\\s+$", "", .) %>%  # Remove extra spaces at the end
gsub("[^a-zA-Z]+$", "", .) %>%
gsub("^Editor's Picks|How to fix VAR.*|The ultimate guide.*|ESPN's .*|Marcotti: .*", "", .) %>%
unique()
print(team_list)
head(20)
team_list <- page %>%
html_nodes("div.article-body h2") %>%
html_text() %>%
gsub("\\s+$", "", .) %>%  # Remove extra spaces at the end
gsub("[^a-zA-Z]+$", "", .) %>%
gsub("^Editor's Picks|How to fix VAR.*|The ultimate guide.*|ESPN's .*|Marcotti: .*", "", .) %>%
unique() %>%
head(20)
print(team_list)
team_list <- team_list[team_list != ""]
print(team_list)
net_score_list <- page %>%
html_nodes("div.article-body h2") %>%
html_text() %>%
gsub("^.* ", "", .) %>%
head(20)
# Extract general statistics for each team
team_stats_list <- page %>%
html_nodes("div.article-body p") %>%
html_text() %>%
grep("Overturns: ", ., value = TRUE)
# Create a data frame
data_df <- data.frame(
team_name = team_list,
net_score = net_score_list,
stats_combined = team_stats_list
)
# Print the resulting data frame
print(data_df)
View(data_df)
# Define stats column mapping
stats_col_mapping <- list(
c('overturns_total', 'Overturns'),
c('overturns_rejected', 'Rejected overturns'),
c('leading_to_goals_for', 'Leading to goals for'),
c('leading_to_goals_against', 'Leading to goals against'),
c('disallowed_goals_for', 'Disallowed goals for'),
c('disallowed_goals_against', 'Disallowed goals against'),
c('net_goal_score', 'Net goal score'),
c('subj_decisions_for', 'Subjective decisions for'),
c('subj_decisions_against', 'Subjective decisions against'),
c('net_subjective_score', 'Net subjective score'),
c('penalties_for', 'Penalties for / against'),
c('penalties_against', 'Penalties for / against')
)
# Create columns
stats_col_list <- sapply(stats_col_mapping, `[`, 1)
for (col in stats_col_list) {
data_df[[col]] <- 0
}
# Update columns based on stats combined information
for (i in 1:nrow(data_df)) {
stats_info <- data_df[i, 'stats_combined']
stats_lines <- strsplit(stats_info, "(?<=\\d)(?=[A-Z])", perl = TRUE)[[1]]
for (line in stats_lines) {
key <- strsplit(line, ': ')[[1]][1]
value <- strsplit(line, ': ')[[1]][2]
for (mapping in stats_col_mapping) {
if (mapping[[2]] == key) {
data_df[i, mapping[[1]]] <- value
}
}
}
}
# Print the resulting dataframe
print(data_df)
View(data_df)
# Amend penalties_for and penalties_against columns
data_df$penalties_for <- str_extract(data_df$penalties_for, "\\d+")
data_df$penalties_against <- str_extract(data_df$penalties_against, "/\\s*(\\d+)")
data_df$penalties_against <- str_replace(data_df$penalties_against, "/\\s*", "")
print(data_df$penalties_against)
View(data_df)
# Add year column
data_df$year <- '2021/2022'
# Drop stats_combined column
data_df <- data_df %>%
select(-stats_combined)
# Print the resulting dataframe
print(data_df)
net_score_columns <- data_df %>%
select(starts_with("net_")) %>%
names()
data_df <- data_df %>%
mutate(across(all_of(net_score_columns), ~ gsub("\\+", "", .)))
print(data_df)
year <- '2021_2022'
csv_file_name <- paste0("Team", year, ".csv")
write.csv(data_df, csv_file_name, row.names = T)
library(rvest)
library(dplyr)
library(stringr)
library(rvest)
library(dplyr)
library(stringr)
# Define the URL
VAR_PAGE_2020_2021 <- "https://www.espn.co.uk/football/story/_/id/37631044/how-var-decisions-affected-every-premier-league-club-2022-23"
# Read the webpage
page <- read_html(VAR_PAGE_2020_2021)
team_list <- page %>%
html_nodes("div.article-body h2") %>%
html_text() %>%
gsub("\\s+$", "", .) %>%  # Remove extra spaces at the end
gsub("[^a-zA-Z]+$", "", .) %>%
gsub("^Editor's Picks|How to fix VAR.*|The ultimate guide.*|ESPN's .*|Marcotti: .*", "", .) %>%
unique() %>%
head(20)
print(team_list)
team_list <- page %>%
html_nodes("div.article-body h2") %>%
html_text() %>%
gsub("\\s+$", "", .) %>%  # Remove extra spaces at the end
gsub("[^a-zA-Z]+$", "", .) %>%
gsub("^Editor's Picks|How to fix VAR.*|The ultimate guide.*|ESPN's .*|Marcotti: .*|The VAR Review.*", "", .) %>%
unique() %>%
head(20)
print(team_list)
team_list <- page %>%
html_nodes("div.article-body h2") %>%
html_text() %>%
gsub("\\s+$", "", .) %>%  # Remove extra spaces at the end
gsub("[^a-zA-Z]+$", "", .) %>%
gsub("^Editor's Picks|How to fix VAR.*|The ultimate guide.*|ESPN's .*|Marcotti: .*|The VAR Review.*", "", .) %>%
unique() %>%
head(20)
print(team_list)
team_list <- page %>%
html_nodes("div.article-body h2") %>%
html_text() %>%
gsub("\\s+$", "", .) %>%  # Remove extra spaces at the end
gsub("[^a-zA-Z]+$", "", .) %>%
gsub("^Editor's Picks|How to fix VAR.*|The ultimate guide.*|ESPN's .*|Marcotti: .*|The VAR Review.*", "", .) %>%
unique()
print(team_list)
team_list <- page %>%
html_nodes("div.article-body h2") %>%
html_text() %>%
gsub("\\s+$", "", .) %>%  # Remove extra spaces at the end
gsub("[^a-zA-Z]+$", "", .) %>%
gsub("^Editor's Picks|How to fix VAR.*|The ultimate guide.*|ESPN's .*|Marcotti: .*|The VAR Review.*", "", .) %>%
unique() %>%
select[1:21]
team_list <- page %>%
html_nodes("div.article-body h2") %>%
html_text() %>%
gsub("\\s+$", "", .) %>%  # Remove extra spaces at the end
gsub("[^a-zA-Z]+$", "", .) %>%
gsub("^Editor's Picks|How to fix VAR.*|The ultimate guide.*|ESPN's .*|Marcotti: .*|The VAR Review.*", "", .) %>%
unique() %>%
team_list <- team_list[1:21]
team_list <- page %>%
html_nodes("div.article-body h2") %>%
html_text() %>%
gsub("\\s+$", "", .) %>%  # Remove extra spaces at the end
gsub("[^a-zA-Z]+$", "", .) %>%
gsub("^Editor's Picks|How to fix VAR.*|The ultimate guide.*|ESPN's .*|Marcotti: .*|The VAR Review.*", "", .) %>%
unique()
team_list <- team_list[1:21]
print(team_list)
team_list <- team_list[2:21]
print(team_list)
team_list <- team_list[team_list != ""]
print(team_list)
net_score_list <- page %>%
html_nodes("div.article-body h2") %>%
html_text() %>%
gsub("^.* ", "", .) %>%
head(20)
print(net_score_list)
net_score_list <- page %>%
html_nodes("div.article-body h2") %>%
html_text() %>%
gsub("^.* ", "", .)
print(net_score_list)
net_score_list <- net_score_list[4:24]
print(net_score_list)
net_score_list <- net_score_list[4:23]
print(net_score_list)
library(rvest)
library(dplyr)
library(stringr)
# Define the URL
VAR_PAGE_2020_2021 <- "https://www.espn.co.uk/football/story/_/id/37631044/how-var-decisions-affected-every-premier-league-club-2022-23"
# Read the webpage
page <- read_html(VAR_PAGE_2020_2021)
team_list <- page %>%
html_nodes("div.article-body h2") %>%
html_text() %>%
gsub("\\s+$", "", .) %>%  # Remove extra spaces at the end
gsub("[^a-zA-Z]+$", "", .) %>%
gsub("^Editor's Picks|How to fix VAR.*|The ultimate guide.*|ESPN's .*|Marcotti: .*|The VAR Review.*", "", .) %>%
unique()
team_list <- team_list[2:21]
print(team_list)
team_list <- team_list[team_list != ""]
print(team_list)
net_score_list <- page %>%
html_nodes("div.article-body h2") %>%
html_text() %>%
gsub("^.* ", "", .)
net_score_list <- net_score_list[4:23]
print(net_score_list)
# Extract general statistics for each team
team_stats_list <- page %>%
html_nodes("div.article-body p") %>%
html_text() %>%
grep("Overturns: ", ., value = TRUE)
# Create a data frame
data_df <- data.frame(
team_name = team_list,
net_score = net_score_list,
stats_combined = team_stats_list
)
View(data_df)
# Print the resulting data frame
print(data_df)
# Define stats column mapping
stats_col_mapping <- list(
c('overturns_total', 'Overturns'),
c('overturns_rejected', 'Rejected overturns'),
c('leading_to_goals_for', 'Leading to goals for'),
c('leading_to_goals_against', 'Leading to goals against'),
c('disallowed_goals_for', 'Disallowed goals for'),
c('disallowed_goals_against', 'Disallowed goals against'),
c('net_goal_score', 'Net goal score'),
c('subj_decisions_for', 'Subjective decisions for'),
c('subj_decisions_against', 'Subjective decisions against'),
c('net_subjective_score', 'Net subjective score'),
c('penalties_for', 'Penalties for / against'),
c('penalties_against', 'Penalties for / against')
)
# Create columns
stats_col_list <- sapply(stats_col_mapping, `[`, 1)
for (col in stats_col_list) {
data_df[[col]] <- 0
}
# Update columns based on stats combined information
for (i in 1:nrow(data_df)) {
stats_info <- data_df[i, 'stats_combined']
stats_lines <- strsplit(stats_info, "(?<=\\d)(?=[A-Z])", perl = TRUE)[[1]]
for (line in stats_lines) {
key <- strsplit(line, ': ')[[1]][1]
value <- strsplit(line, ': ')[[1]][2]
for (mapping in stats_col_mapping) {
if (mapping[[2]] == key) {
data_df[i, mapping[[1]]] <- value
}
}
}
}
# Print the resulting dataframe
print(data_df)
# Amend penalties_for and penalties_against columns
data_df$penalties_for <- str_extract(data_df$penalties_for, "\\d+")
data_df$penalties_against <- str_extract(data_df$penalties_against, "/\\s*(\\d+)")
data_df$penalties_against <- str_replace(data_df$penalties_against, "/\\s*", "")
print(data_df$penalties_against)
# Add year column
data_df$year <- '2022/2023'
# Drop stats_combined column
data_df <- data_df %>%
select(-stats_combined)
# Print the resulting dataframe
print(data_df)
net_score_columns <- data_df %>%
select(starts_with("net_")) %>%
names()
data_df <- data_df %>%
mutate(across(all_of(net_score_columns), ~ gsub("\\+", "", .)))
print(data_df)
year <- '2022_2023'
csv_file_name <- paste0("Team", year, ".csv")
write.csv(data_df, csv_file_name, row.names = T)
library(rvest)
library(dplyr)
library(stringr)
# Define the URL
VAR_PAGE_2020_2021 <- "https://www.espn.co.uk/football/story/_/id/37631044/how-var-decisions-affected-every-premier-league-club-2022-23"
# Read the webpage
page <- read_html(VAR_PAGE_2020_2021)
VAR_team <- page %>%
html_nodes("aside.inline.editorial.float-r") %>%
html_text()
VAR_team <- VAR_team[2:3]
library(rvest)
library(dplyr)
library(stringr)
library(tidyr)
# Define the URL
VAR_PAGE_2020_2021 <- "https://www.espn.co.uk/football/story/_/id/37631044/how-var-decisions-affected-every-premier-league-club-2022-23"
# Read the webpage
page <- read_html(VAR_PAGE_2020_2021)
VAR_team <- page %>%
html_nodes("aside.inline.editorial.float-r") %>%
html_text()
print(VAR_team)
VAR_team <- VAR_team[3:4]
print(VAR_team)
split_lines <- strsplit(VAR_team, "\n")
split_lines <- lapply(split_lines, function(x) x[-1])
print(split_lines)
decisions_for <- list(split_lines[[2]])
decisions_against <- list(split_lines[[1]])
# Initialize empty data frame
data_df_for <- data.frame(team = character(0), count = character(0))
data_df_against <- data.frame(team = character(0), count = character(0))
# Iterate through each list and extract data
for (lines in decisions_for) {
team <- str_extract(lines, "([\\w\\s&]+)")
team <- gsub("\\d+", "", team)
count <- str_extract(lines, "\\d+")
data_df_for <- data_df_for %>%
add_row(team = team, count = count)
}
for (lines in decisions_against) {
team <- str_extract(lines, "([\\w\\s&]+)")
team <- gsub("\\d+", "", team)
count <- str_extract(lines, "\\d+")
data_df_against <- data_df_against %>%
add_row(team = team, count = count)
}
# Print the resulting data frame
print(data_df)
combined_data <- full_join(data_df_for, data_df_against, by = "team")
# Rename columns
colnames(combined_data) <- c("team", "count_for", "count_against")
# Print the combined data frame
print(combined_data)
combined_data$year <- '2022/2023'
setwd("C:/Users/ohagg/OneDrive - University College London/Desktop/VAR_scraping")
# Assuming you have a data frame called combined_data and a year variable
year <- '2021_2022'
csv_file_name <- paste0("VAR_decisions", year, ".csv")
write.csv(combined_data, csv_file_name, row.names = T)
# Assuming you have a data frame called combined_data and a year variable
year <- '2022_2023'
csv_file_name <- paste0("VAR_decisions", year, ".csv")
write.csv(combined_data, csv_file_name, row.names = T)
library(rvest)
library(dplyr)
library(stringr)
library(tidyr)
# Define the URL
VAR_PAGE_2020_2021 <- "https://www.espn.co.uk/football/story/_/id/37619801/how-var-decisions-affected-every-premier-league-club-2021-22"
# Read the webpage
page <- read_html(VAR_PAGE_2020_2021)
VAR_team <- page %>%
html_nodes("aside.inline.editorial.float-r") %>%
html_text()
print(VAR_team)
VAR_team <- VAR_team[2:3]
split_lines <- strsplit(VAR_team, "\n")
split_lines <- lapply(split_lines, function(x) x[-1])
print(split_lines)
decisions_for <- list(split_lines[[2]])
decisions_against <- list(split_lines[[1]])
# Initialize empty data frame
data_df_for <- data.frame(team = character(0), count = character(0))
data_df_against <- data.frame(team = character(0), count = character(0))
# Iterate through each list and extract data
for (lines in decisions_for) {
team <- str_extract(lines, "([\\w\\s&]+)")
team <- gsub("\\d+", "", team)
count <- str_extract(lines, "\\d+")
data_df_for <- data_df_for %>%
add_row(team = team, count = count)
}
for (lines in decisions_against) {
team <- str_extract(lines, "([\\w\\s&]+)")
team <- gsub("\\d+", "", team)
count <- str_extract(lines, "\\d+")
data_df_against <- data_df_against %>%
add_row(team = team, count = count)
}
# Print the resulting data frame
print(data_df)
combined_data <- full_join(data_df_for, data_df_against, by = "team")
# Rename columns
colnames(combined_data) <- c("team", "count_for", "count_against")
# Print the combined data frame
print(combined_data)
combined_data$year <- '2021/2022'
setwd("C:/Users/ohagg/OneDrive - University College London/Desktop/VAR_scraping")
# Assuming you have a data frame called combined_data and a year variable
year <- '2021_2022'
csv_file_name <- paste0("VAR_decisions", year, ".csv")
write.csv(combined_data, csv_file_name, row.names = T)
library(rvest)
library(dplyr)
library(stringr)
library(tidyr)
# Define the URL
VAR_PAGE_2020_2021 <- "https://www.espn.co.uk/football/story/_/id/37587139/how-var-decisions-affected-every-premier-league-club-2020-21"
# Read the webpage
page <- read_html(VAR_PAGE_2020_2021)
VAR_team <- page %>%
html_nodes("aside.inline.editorial.float-r") %>%
html_text()
print(VAR_team)
library(rvest)
library(dplyr)
library(stringr)
library(tidyr)
# Define the URL
VAR_PAGE_2020_2021 <- "https://www.espn.com/soccer/english-premier-league/story/3929823/how-var-decisions-have-affected-every-premier-league-club"
# Read the webpage
page <- read_html(VAR_PAGE_2020_2021)
VAR_team <- page %>%
html_nodes("aside.inline.editorial.float-r") %>%
html_text()
VAR_team <- VAR_team[2:3]
split_lines <- strsplit(VAR_team, "\n")
split_lines <- lapply(split_lines, function(x) x[-1])
print(split_lines)
decisions_for <- list(split_lines[[1]])
decisions_against <- list(split_lines[[2]])
# Combine the decisions_for and decisions_against lists
#combined_decisions <- c(decisions_for, decisions_against)
# Initialize empty data frame
data_df_for <- data.frame(team = character(0), count = character(0))
data_df_against <- data.frame(team = character(0), count = character(0))
# Iterate through each list and extract data
for (lines in decisions_for) {
team <- str_extract(lines, "([\\w\\s&]+)")
team <- gsub("\\d+", "", team)
count <- str_extract(lines, "\\d+")
data_df_for <- data_df_for %>%
add_row(team = team, count = count)
}
for (lines in decisions_against) {
team <- str_extract(lines, "([\\w\\s&]+)")
team <- gsub("\\d+", "", team)
count <- str_extract(lines, "\\d+")
data_df_against <- data_df_against %>%
add_row(team = team, count = count)
}
# Print the resulting data frame
print(data_df)
combined_data <- full_join(data_df_for, data_df_against, by = "team")
# Rename columns
colnames(combined_data) <- c("team", "count_for", "count_against")
# Print the combined data frame
print(combined_data)
combined_data$year <- '2019/2020'
setwd("C:/Users/ohagg/OneDrive - University College London/Desktop/VAR_scraping")
# Assuming you have a data frame called combined_data and a year variable
year <- '2019_2020'
csv_file_name <- paste0("VAR_decisions", year, ".csv")
write.csv(combined_data, csv_file_name, row.names = T)
View(combined_data)
knitr::opts_chunk$set(echo = TRUE)
library(rvest)
library(dplyr)
library(stringr)
library(tidyr)
setwd("C:/Users/ohagg/OneDrive - University College London/Desktop/VAR_scraping")
# Define the URL
VAR_PAGE_2020_2021 <- "https://www.espn.com/soccer/english-premier-league/story/3929823/how-var-decisions-have-affected-every-premier-league-club"
